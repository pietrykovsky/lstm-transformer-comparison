{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import string\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "filepath = \"cleaned_text.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_unicode(text):\n",
    "    if isinstance(text, bytes):\n",
    "        return text.decode('utf-8', 'ignore')\n",
    "    elif isinstance(text, str):\n",
    "        return text\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported string type\")\n",
    "\n",
    "# Function to filter text\n",
    "def filter_text(text, allowed_chars):\n",
    "    return ''.join([char for char in text if char in allowed_chars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\u000b\f\n",
      "55474549\n"
     ]
    }
   ],
   "source": [
    "with open(filepath, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "    content = file.read()\n",
    "    content = ensure_unicode(content)\n",
    "    all_chars = string.printable\n",
    "    filtered_text = filter_text(content, all_chars)\n",
    "\n",
    "# Use filtered text as 'all_text'\n",
    "all_text = filtered_text\n",
    "number_of_char = len(all_text)\n",
    "\n",
    "all_chars = string.printable\n",
    "number_of_chars = len(all_chars)\n",
    "print(all_chars)\n",
    "print(len(all_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embed = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embed(x)\n",
    "        out, (hidden, cell) = self.lstm(out.unsqueeze(1), (hidden, cell))\n",
    "        out = self.fc(out.reshape(out.shape[0], -1))\n",
    "        return out, (hidden, cell)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        return hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self):\n",
    "        self.chunk_len = 256 # puścić zwiększone do 350 dla lr=0.003 lr=0.0035 i lr=0.004\n",
    "        self.num_epochs = 5000\n",
    "        self.batch_size = 1\n",
    "        self.print_every = 25\n",
    "        self.hidden_size = 256\n",
    "        self.num_layers = 3  # Nie ruszaj\n",
    "        self.lr = 0.0006 # puścić to oraz dodatkowo bez ruszania chunk_len lr=0.004\n",
    "        # czyli 5 puszczeń sieci :\n",
    "        # 1: chunk_len=256 lr=0.0035\n",
    "        # 2: chunk_len=256 lr=0.004\n",
    "        # 3: chunk_len=350 lr=0.003\n",
    "        # 4: chunk_len=350 lr=0.0035\n",
    "        # 5: chunk_len=350 lr=0.004\n",
    "        self.rnn = RNN(number_of_chars, self.hidden_size, self.num_layers, number_of_chars).to(device)\n",
    "\n",
    "    def char_tensor(self, string):\n",
    "        tensor = torch.zeros(len(string)).long()\n",
    "        for c in range(len(string)):\n",
    "            tensor[c] = all_chars.index(string[c])\n",
    "        return tensor\n",
    "\n",
    "    def get_random_batch(self):\n",
    "        start_index = random.randint(0, len(all_text) - self.chunk_len)\n",
    "        end_index = start_index + self.chunk_len + 1\n",
    "        text_str = all_text[start_index:end_index]\n",
    "        text_input = torch.zeros(self.batch_size, self.chunk_len)\n",
    "        text_target = torch.zeros(self.batch_size, self.chunk_len)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            text_input[i, :] = self.char_tensor(text_str[:-1])\n",
    "            text_target[i, :] = self.char_tensor(text_str[1:])\n",
    "        return text_input.long(), text_target.long()\n",
    "\n",
    "    def generate(self, initial_string='T', prediction_length=100, temperature=0.85):\n",
    "        hidden, cell = self.rnn.init_hidden(batch_size=self.batch_size)\n",
    "        initial_input = self.char_tensor(initial_string)\n",
    "        predicted = initial_string\n",
    "\n",
    "        for p in range(len(initial_string) - 1):\n",
    "            _, (hidden, cell) = self.rnn(initial_input[p].view(1).to(device), hidden, cell)\n",
    "\n",
    "        last_char = initial_input[-1]\n",
    "\n",
    "        for p in range(prediction_length):\n",
    "            output, (hidden, cell) = self.rnn(last_char.view(1).to(device), hidden, cell)\n",
    "            output_dist = output.data.view(-1).div(temperature).exp()\n",
    "            top_char = torch.multinomial(output_dist, 1)[0]\n",
    "            predicted_char = all_chars[top_char]\n",
    "            predicted += predicted_char\n",
    "            last_char = self.char_tensor(predicted_char)\n",
    "        return predicted\n",
    "\n",
    "    def train(self):\n",
    "        optimizer = torch.optim.Adam(self.rnn.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        writer = SummaryWriter(f'runs/TextGenerationExperiment')\n",
    "        print(\"=> starting training :)\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in tqdm(range(1, self.num_epochs + 1), desc=\"Training\", unit=\"epoch\"):\n",
    "            inp, target = self.get_random_batch()\n",
    "            hidden, cell = self.rnn.init_hidden(batch_size=self.batch_size)\n",
    "            self.rnn.zero_grad()\n",
    "            loss = 0\n",
    "            inp = inp.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            for c in range(self.chunk_len):\n",
    "                output, (hidden, cell) = self.rnn(inp[:, c], hidden, cell)\n",
    "                loss += criterion(output, target[:, c])\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.rnn.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            loss = loss.item() / self.chunk_len\n",
    "\n",
    "            writer.add_scalar('Training Loss', loss, global_step=epoch)\n",
    "\n",
    "            if epoch % self.print_every == 0:\n",
    "                print(f'Loss: {loss}')\n",
    "                print(self.generate())\n",
    "                elapsed_time = time.time() - start_time\n",
    "                estimated_total_time = elapsed_time / epoch * self.num_epochs\n",
    "                print(f'Estimated total training time: {estimated_total_time // 60} minutes')\n",
    "\n",
    "        # Save the model after training\n",
    "        torch.save(self.rnn.state_dict(), 'trained_rnn.pth')\n",
    "        print(\"=> training finished and model saved :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gennames = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "=> starting training :)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/5000 [00:00<?, ?epoch/s]\n"
     ]
    },
   ],
   "source": [
    "gennames.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "def load_model(generator, model_path='trained_rnn.pth'):\n",
    "    generator.rnn.load_state_dict(torch.load(model_path))\n",
    "    generator.rnn.eval()\n",
    "    print(\"Model loaded.\")\n",
    "\n",
    "# Load the model\n",
    "load_model(gennames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(generator, initial_string, length=100, temperature=0.6):\n",
    "    generated_text = generator.generate(initial_string, length, temperature)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Detective John entered the dimly lit room, only to find a pool of blood next to the words, and his wife was not may not the procom\"\n",
      "\n",
      "\"The suspect had a solid alibi, but something in his eyes told the inspector that he said to the fair sense of the fine she state of the particular as the carest with the man and app\"\n",
      "\n",
      "\"She never expected the secret message hidden in the old locket would lead her to for the bottle men upon the same in the latter. And the ligh\"\n",
      "\n",
      "\"As the clock struck midnight, the eerie silence was broken by the sound of him with the various and other so the laid to the restable\n",
      "and have been has not discurriage with a many are the\n",
      "declarable chart of\n",
      "the police of the anger.\n",
      "He repeated the clue in his latter side of\"\n",
      "\n",
      "\"The missing pages from the diary hinted at a conspiracy that went all the way to action of the find the companions, with the bank of the\"\n",
      "\n",
      "\"With every step in the abandoned warehouse, Mark could feel someone watching him from the charge are a goodness. In the same knew s\"\n",
      "\n",
      "\"The coded note left at the crime scene was the key to unraveling the mystery of the endeath time to make the bone, the must the firming and one of the perhaps the subject the subbr\"\n",
      "\n",
      "\"Just as she was about to give up, a mysterious figure emerged from the shadows and perhaps the entreature in his earth as tell the in originati\"\n",
      "\n",
      "\"The old detective had seen many cases, but nothing as chilling as the one involving to must be suppose a repeated the strength of person from the\n",
      "departicistical realical all the man was the Englishess who have an accidental companion\"\n",
      "\n",
      "\"Every clue pointed to the butler, but the real mastermind behind the crimes was to see signed a man the company in the several cam\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark_data = [\n",
    "    (\"Detective John entered the dimly lit room, only to find a pool of blood next to \", 50),\n",
    "    (\"The suspect had a solid alibi, but something in his eyes told the inspector that \", 100),\n",
    "    (\"She never expected the secret message hidden in the old locket would lead her to \", 60),\n",
    "    (\"As the clock struck midnight, the eerie silence was broken by the sound of \", 200),\n",
    "    (\"The missing pages from the diary hinted at a conspiracy that went all the way to \", 55),\n",
    "    (\"With every step in the abandoned warehouse, Mark could feel someone watching him from \", 45),\n",
    "    (\"The coded note left at the crime scene was the key to unraveling the mystery of \", 100),\n",
    "    (\"Just as she was about to give up, a mysterious figure emerged from the shadows and \", 60),\n",
    "    (\"The old detective had seen many cases, but nothing as chilling as the one involving \", 150),\n",
    "    (\"Every clue pointed to the butler, but the real mastermind behind the crimes was \", 50),\n",
    "]\n",
    "\n",
    "for prompt, max_new_tokens in benchmark_data:\n",
    "    print(f\"\\\"{generate_text(gennames, prompt, max_new_tokens)}\\\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
